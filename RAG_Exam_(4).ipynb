{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdulazizkoja1/T5/blob/main/RAG_Exam_(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m83H0SRDK01q"
      },
      "source": [
        "# Traffic Violation RAG System\n",
        "In this exam, you will implement a Retrieval-Augmented Generation (RAG) system that uses a language model and a vector database to answer questions about traffic violations. The goal is to generate answers with relevant data based on a dataset of traffic violations and fines.\n",
        "\n",
        "Here are helpful resources:\n",
        "* [LangChain](https://www.langchain.com/)\n",
        "* [groq cloud documentation](https://console.groq.com/docs/models)\n",
        "* [LangChain HuggingFace](https://python.langchain.com/docs/integrations/text_embedding/sentence_transformers/)\n",
        "* [Chroma Vector Store](https://python.langchain.com/docs/integrations/vectorstores/chroma/)\n",
        "* [Chroma Website](https://docs.trychroma.com/getting-started)\n",
        "* [ChatGroq LangChain](https://python.langchain.com/docs/integrations/chat/groq/)\n",
        "* [LLM Chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain)\n",
        "\n",
        "Dataset [source](https://www.moi.gov.sa/wps/portal/Home/sectors/publicsecurity/traffic/contents/!ut/p/z0/04_Sj9CPykssy0xPLMnMz0vMAfIjo8ziDTxNTDwMTYy83V0CTQ0cA71d_T1djI0MXA30gxOL9L30o_ArApqSmVVYGOWoH5Wcn1eSWlGiH1FSlJiWlpmsagBlKCQWqRrkJmbmqRqUZebngB2gUJAKdERJZmqxfkG2ezgAhzhSyw!!/)\n",
        "\n",
        "Some installs if needed:\n",
        "```python\n",
        "!pip install langchain_huggingface langchain langchain-community langchain_chroma Chroma langchain_groq LLMChain\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5MtVtxvxqd7"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d khaledzsa/dataset\n",
        "# !unzip dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKe3G7bqK-W6"
      },
      "source": [
        "## Step 1: Install Required Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewOnaf7BLBQ8"
      },
      "source": [
        "To begin, install the necessary libraries for this project. The libraries include `LangChain` for building language model chains, and `Chroma` for managing a vector database."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain langchain_community unstructured sentence_transformers tiktoken chromadb langchain_chroma langchain_groq"
      ],
      "metadata": {
        "id": "sjiPx3oXTfWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI7_KEjILJZ8"
      },
      "source": [
        "## Step 2: Load the Traffic Violations Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY6U8FxlLLON"
      },
      "source": [
        "You are provided with a dataset of traffic violations. Load the CSV file into a pandas DataFrame and preview the first few rows of the dataset using `.head()`. You can also try and see the dataset's characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzTMfTyJ_tZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "eb4acbef-9de3-4b46-8553-92da56294814"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            المخالفة  \\\n",
              "0  قيادة المركبة في الأسواق التي لا يسمح بالقيادة...   \n",
              "1   ترك المركبة مفتوحة وفي وضع التشغيل بعد مغادرتها.   \n",
              "2                       عدم وجود تأمين ساري للمركبة.   \n",
              "3      عبور المشاة للطرق من غير الأماكن المخصصة لهم.   \n",
              "4              عدم تقيد المشاة بالإشارات الخاصة بهم.   \n",
              "\n",
              "                          الغرامة  \n",
              "0  الغرامة المالية 100 - 150 ريال  \n",
              "1  الغرامة المالية 100 - 150 ريال  \n",
              "2  الغرامة المالية 100 - 150 ريال  \n",
              "3  الغرامة المالية 100 - 150 ريال  \n",
              "4  الغرامة المالية 100 - 150 ريال  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-699f7f7f-3a7d-4685-bd83-166e4b366012\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>المخالفة</th>\n",
              "      <th>الغرامة</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>قيادة المركبة في الأسواق التي لا يسمح بالقيادة...</td>\n",
              "      <td>الغرامة المالية 100 - 150 ريال</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ترك المركبة مفتوحة وفي وضع التشغيل بعد مغادرتها.</td>\n",
              "      <td>الغرامة المالية 100 - 150 ريال</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>عدم وجود تأمين ساري للمركبة.</td>\n",
              "      <td>الغرامة المالية 100 - 150 ريال</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>عبور المشاة للطرق من غير الأماكن المخصصة لهم.</td>\n",
              "      <td>الغرامة المالية 100 - 150 ريال</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>عدم تقيد المشاة بالإشارات الخاصة بهم.</td>\n",
              "      <td>الغرامة المالية 100 - 150 ريال</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-699f7f7f-3a7d-4685-bd83-166e4b366012')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-699f7f7f-3a7d-4685-bd83-166e4b366012 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-699f7f7f-3a7d-4685-bd83-166e4b366012');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d851ca26-0569-4ad6-9e87-a00ebc28e061\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d851ca26-0569-4ad6-9e87-a00ebc28e061')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d851ca26-0569-4ad6-9e87-a00ebc28e061 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 104,\n  \"fields\": [\n    {\n      \"column\": \"\\u0627\\u0644\\u0645\\u062e\\u0627\\u0644\\u0641\\u0629\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 104,\n        \"samples\": [\n          \"\\u0627\\u0644\\u0642\\u064a\\u0627\\u062f\\u0629 \\u0628\\u0631\\u062e\\u0635\\u0629 \\u0642\\u064a\\u0627\\u062f\\u0629 \\u0635\\u0644\\u0627\\u062d\\u064a\\u062a\\u0647\\u0627 \\u0645\\u0646\\u062a\\u0647\\u064a\\u0629.\",\n          \"\\u0633\\u064a\\u0631 \\u0627\\u0644\\u0645\\u0631\\u0643\\u0628\\u0629 \\u0628\\u0644\\u0627 \\u0644\\u0648\\u062d\\u0629 \\u0623\\u0645\\u0627\\u0645\\u064a\\u0629.\",\n          \"\\u0642\\u064a\\u0627\\u062f\\u0629 \\u0627\\u0644\\u0645\\u0631\\u0643\\u0628\\u0629 \\u0628\\u0644\\u0648\\u062d\\u0627\\u062a \\u063a\\u064a\\u0631 \\u0648\\u0627\\u0636\\u062d\\u0629 \\u0623\\u0648 \\u0628\\u0647\\u0627 \\u062a\\u0644\\u0641.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0627\\u0644\\u063a\\u0631\\u0627\\u0645\\u0629\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\u0627\\u0644\\u063a\\u0631\\u0627\\u0645\\u0629 \\u0627\\u0644\\u0645\\u0627\\u0644\\u064a\\u0629 100 - 150 \\u0631\\u064a\\u0627\\u0644\",\n          \"\\u0627\\u0644\\u063a\\u0631\\u0627\\u0645\\u0629 \\u0627\\u0644\\u0645\\u0627\\u0644\\u064a\\u0629 150 - 300 \\u0631\\u064a\\u0627\\u0644\",\n          \"\\u0627\\u0644\\u063a\\u0631\\u0627\\u0645\\u0629 \\u0627\\u0644\\u0645\\u0627\\u0644\\u064a\\u0629 3000 - 6000 \\u0631\\u064a\\u0627\\u0644\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "import markdown\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "df = pd.read_csv('Dataset.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Hs28tz2LbFx"
      },
      "source": [
        "## Step 3: Create Markdown Content from the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiNAqLhELd_S"
      },
      "source": [
        "For each traffic violation in the dataset, you will generate markdown text that describes the violation and the associated fine. Create a loop to iterate through the dataset and store the generated markdown in a list. Each fine should look like this:\n",
        "\n",
        "**المخالفة** - الغرامة"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daP6wjbA_km0"
      },
      "outputs": [],
      "source": [
        "directory = 'data/markdown_files'\n",
        "os.makedirs(directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "\n",
        "    title = df['المخالفة'].iloc[i]\n",
        "    content = df['الغرامة'].iloc[i]\n",
        "\n",
        "    markdown_content = f\"# {title}\\n\\n\"\n",
        "    markdown_content += f\"{content}\\n\\n\"\n",
        "\n",
        "    with open(f'{directory}/{i}.md', 'w', encoding='utf-8') as file:\n",
        "        file.write(markdown_content)"
      ],
      "metadata": {
        "id": "4lWwhzsC9v5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markdown_texts = []\n",
        "for filename in os.listdir(directory):\n",
        "  if filename.endswith(\".md\"):\n",
        "    with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "      markdown_content = file.read()\n",
        "      html_content = markdown.markdown(markdown_content)\n",
        "      markdown_texts.append(html_content)"
      ],
      "metadata": {
        "id": "2i7f8Ay69y2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifkMDS5SLui4"
      },
      "source": [
        "## Step 4: Chunk the Markdown Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJxNEV5yLxMu"
      },
      "source": [
        "Using LangChain's `RecursiveCharacterTextSplitter`, split the markdown texts into smaller chunks that will be stored in the vector database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf3-3j9iALUN"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "documents = text_splitter.create_documents(markdown_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EviXuMjfL2Gj"
      },
      "source": [
        "## Step 5: Generate Embeddings for the Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAUq12UtL5OJ"
      },
      "source": [
        "Generate embeddings for the chunks of text using HuggingFace's pre-trained Arabic language model. These embeddings will be stored in a `Chroma` vector store."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")"
      ],
      "metadata": {
        "id": "mRXl4MN9-Da-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4-YlqMKAeGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0743329e-26c9-4471-c775-fb9f196883b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name aubmindlab/bert-base-arabertv2. Creating a new one with mean pooling.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "PRESIST_DIRECTORY = '/content/chroma_db'\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"aubmindlab/bert-base-arabertv2\")\n",
        "persist_directory = \"./chroma_db\"\n",
        "db = Chroma(persist_directory=persist_directory, embedding_function=embedding_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l32elHl2L-ob"
      },
      "source": [
        "## Step 6: Define the RAG Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1zWp3KfMAld"
      },
      "source": [
        "Define a custom prompt template in Arabic to retrieve traffic violation-related answers based on the context. Ensure the template greets the user first, states that the information provided could be incorrect, and advises the user to visit the traffic initiative website to verify. Additionally, provide the user with advice in Arabic, ensuring it stays within the given context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdy4qbn_CYTn"
      },
      "outputs": [],
      "source": [
        "PROMPT_TEMPLATE=\"\"\"\n",
        "  انت ضابط مرور، يجب عليك ان الرجوع الى البيانات المعطاه لك لاعطاء الغرامة المناسبة. و اعطي الاجابة بالعربي\n",
        "  بالاضافة ابدأ بالسلام في بداية الجملة.\n",
        "  و في النهاية انصح المخالف\n",
        "  و اذا ليست المخالفة موجودة فلا تجاوب و قل لا اعلم الاجابة\n",
        "  المعلومات: {context}\n",
        "  الغرامة: {question}\n",
        "  إجابتك:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvfcCIjgMG34"
      },
      "source": [
        "## Step 7: Initialize the Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lvHUsNTMIvX"
      },
      "source": [
        "Initialize the language model using the Groq API. Set up the model with a specific configuration, including the API key, temperature setting, and model name."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = \"\"\n",
        "llm = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "id": "no4zVdh7-NH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM_tszFvHN6m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3T-2Fy9MLPa"
      },
      "source": [
        "## Step 8: Create the LLM Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCcrmiA2MOOi"
      },
      "source": [
        "Now, you will create an LLM Chain that combines the language model and the prompt template you defined. This chain will be used to generate responses based on the retrieved context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1EEjdquHrTL"
      },
      "outputs": [],
      "source": [
        "MODEL = LLMChain(llm=llm,\n",
        "                 prompt=prompt_template,\n",
        "                 verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di48NYGQMQtS"
      },
      "source": [
        "## Step 9: Implement the Query Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huXN44hwMS07"
      },
      "source": [
        "Create a function `query_rag` that will take a user query as input, retrieve relevant context from the vector store, and use the language model to generate a response based on that context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJLrEKqzHhDy"
      },
      "outputs": [],
      "source": [
        "def query_rag(query: str):\n",
        "    similarity_search_results = db.similarity_search_with_score(query, k=4)\n",
        "    context_text = \"\\n\\n\".join([doc.page_content for doc, _score in similarity_search_results])\n",
        "\n",
        "    rag_response = MODEL.invoke({\"context\": context_text, \"question\": query})\n",
        "\n",
        "    return rag_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iRfIjyzPLC_"
      },
      "source": [
        "## Step 10: Inference - Running Queries in the RAG System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iTaUjpWPOyt"
      },
      "source": [
        "In this final step, you will implement an inference pipeline to handle real-time queries. You will allow the system to retrieve the most relevant violations and fines based on a user's input and generate a response.\n",
        "\n",
        "1. Inference Workflow:\n",
        "\n",
        "  * The user inputs a query (e.g., \"ماهي عقوبة عدم الوقوف وقوفاً تاماً عند إشارة؟\").\n",
        "  * The system searches for the most relevant context from the traffic violation vector store.\n",
        "  * It generates an answer and advice based on the context.\n",
        "\n",
        "2. Goal:\n",
        "  * Run the inference to answer questions based on the traffic violation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k4BmIAHH38X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536941a4-1e1c-4bbf-bedf-fb0c8e4b5f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  انت ضابط مرور، يجب عليك ان الرجوع الى البيانات المعطاه لك لاعطاء الغرامة المناسبة. و اعطي الاجابة بالعربي\n",
            "  بالاضافة ابدأ بالسلام في بداية الجملة.\n",
            "  و في النهاية انصح المخالف\n",
            "  المعلومات: \n",
            "  الغرامة: ماهي عقوبة عدم الوقوف وقوفاً تاماً عند إشارة؟\n",
            "  إجابتك:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': '',\n",
              " 'question': 'ماهي عقوبة عدم الوقوف وقوفاً تاماً عند إشارة؟',\n",
              " 'text': 'سلام عليكم،\\n\\nوفقاً لبياناتي، فإن الغرامة المناسبة لعدم الوقوف وقوفاً تاماً عند إشارة هي 250 ريال.\\n\\nأنا أنصح المخالف بالتزام الإشارات المرورية والوقوف وقوفاً تاماً عند الإشارات لمنع حدوث أي مشاكل أو حوادث على الطريق.\\n\\nأمل أن يتعلم المخالف من هذه التجربة ويحافظ على السلامة على الطريق في المستقبل.\\n\\nأشكرك على الاهتمام بالسلامة على الطريق.'}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "response = query_rag(\"ماهي عقوبة عدم الوقوف وقوفاً تاماً عند إشارة؟\")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "7kFUcV5aAnjp",
        "outputId": "9fc7890b-3c32-4071-9fca-f3474797c46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'سلام عليكم،\\n\\nوفقاً لبياناتي، فإن الغرامة المناسبة لعدم الوقوف وقوفاً تاماً عند إشارة هي 250 ريال.\\n\\nأنا أنصح المخالف بالتزام الإشارات المرورية والوقوف وقوفاً تاماً عند الإشارات لمنع حدوث أي مشاكل أو حوادث على الطريق.\\n\\nأمل أن يتعلم المخالف من هذه التجربة ويحافظ على السلامة على الطريق في المستقبل.\\n\\nأشكرك على الاهتمام بالسلامة على الطريق.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import discord\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "intents = discord.Intents.default()\n",
        "intents.message_content = True\n",
        "\n",
        "client = discord.Client(intents=intents)\n",
        "\n",
        "@client.event\n",
        "async def on_ready():\n",
        "    print(f'We have logged in as {client.user}')\n",
        "\n",
        "@client.event\n",
        "async def on_message(message):\n",
        "    if message.author == client.user:\n",
        "        return\n",
        "\n",
        "    if message.content.startswith('!ask'):\n",
        "      question = message.content[4:]\n",
        "      response = query_rag(question)\n",
        "      await message.channel.send(response['text'])\n",
        "\n",
        "\n",
        "    if message.content.startswith('!hello'):\n",
        "      await message.channel.send('Hello! This bot is running on Google Colab!')\n",
        "\n",
        "\n",
        "\n",
        "client.run(token)\n",
        "\n",
        "import time\n",
        "while True:\n",
        "    time.sleep(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "5S3s2qfcAxzq",
        "outputId": "6de0bd9a-1d8a-4481-c2c4-8b4d16e921df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[30;1m2024-09-19 16:06:05\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2024-09-19 16:06:05\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "INFO:discord.client:logging in using static token\n",
            "\u001b[30;1m2024-09-19 16:06:06\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: 9b16605f0e86ffa4904c8471123f8036).\n",
            "\u001b[30;1m2024-09-19 16:06:06\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: 9b16605f0e86ffa4904c8471123f8036).\n",
            "INFO:discord.gateway:Shard ID None has connected to Gateway (Session ID: 9b16605f0e86ffa4904c8471123f8036).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have logged in as T5-Answering-Bot#7079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  انت ضابط مرور، يجب عليك ان الرجوع الى البيانات المعطاه لك لاعطاء الغرامة المناسبة. و اعطي الاجابة بالعربي\n",
            "  بالاضافة ابدأ بالسلام في بداية الجملة.\n",
            "  و في النهاية انصح المخالف\n",
            "  المعلومات: \n",
            "  الغرامة:  عدم وجود تأمين ساري للمركبة.\n",
            "  إجابتك:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  انت ضابط مرور، يجب عليك ان الرجوع الى البيانات المعطاه لك لاعطاء الغرامة المناسبة. و اعطي الاجابة بالعربي\n",
            "  بالاضافة ابدأ بالسلام في بداية الجملة.\n",
            "  و في النهاية انصح المخالف\n",
            "  المعلومات: \n",
            "  الغرامة:  ماهي عقوبة عدم الوقوف وقوفاً تاماً عند إشارة؟\n",
            "  إجابتك:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.callbacks.manager:Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "  انت ضابط مرور، يجب عليك ان الرجوع الى البيانات المعطاه لك لاعطاء الغرامة المناسبة. و اعطي الاجابة بالعربي\n",
            "  بالاضافة ابدأ بالسلام في بداية الجملة.\n",
            "  و في النهاية انصح المخالف\n",
            "  المعلومات: \n",
            "  الغرامة:  ماهو التفاح\n",
            "  إجابتك:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-cf838f050455>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install discord"
      ],
      "metadata": {
        "id": "jOyQAs_OBOTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SQydxylBRK4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}